{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def analyze_text(text):\n",
    "\treturn nlp(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  [0, 1, 2, 3, 4, 5]\n",
      "Orth: [7859011591137717335, 2772908615185555060, 11283501755624150392, 5533571732986600803, 17365054503653917826, 12646065887601541794]\n",
      "Text:  ['It', 'costs', '$', '1', 'million', '.']\n",
      "is_alpha:  [True, True, False, False, True, False]\n",
      "is_punct:  [False, False, False, False, False, True]\n",
      "like_num:  [False, False, False, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "# # # Tokenization Explained # # #\n",
    "doc = analyze_text('It costs $1 million.')\n",
    "print(\"Index: \", [token.i for token in doc])\n",
    "print(\"Orth:\", [token.orth for token in doc]) \n",
    "print(\"Text: \", [token.text for token in doc]) \n",
    "print(\"is_alpha: \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct: \", [token.is_punct for token in doc])\n",
    "print(\"like_num: \", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determiner\n",
      "nominal subject\n",
      "Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "# # # spaCy Labels Explained # # #\n",
    "def spacy_explain(label):\n",
    "\tprint(spacy.explain(label))\n",
    "\n",
    "\n",
    "spacy_explain('DET')\n",
    "spacy_explain('nsubj')\n",
    "spacy_explain('GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of speech John --> PROPN\n",
      "Dependency parser John --> compound\n",
      "Head Text Smith --> John\n",
      "Part of speech Smith --> PROPN\n",
      "Dependency parser Smith --> nsubj\n",
      "Head Text ate --> Smith\n",
      "Part of speech ate --> VERB\n",
      "Dependency parser ate --> ROOT\n",
      "Head Text ate --> ate\n",
      "Part of speech a --> DET\n",
      "Dependency parser a --> det\n",
      "Head Text pizza --> a\n",
      "Part of speech pizza --> NOUN\n",
      "Dependency parser pizza --> dobj\n",
      "Head Text ate --> pizza\n",
      "Part of speech yesterday --> NOUN\n",
      "Dependency parser yesterday --> npadvmod\n",
      "Head Text ate --> yesterday\n",
      "Part of speech ! --> PUNCT\n",
      "Dependency parser ! --> punct\n",
      "Head Text ate --> !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9d550cd9488d48b8adabbf781f67318d-0\" class=\"displacy\" width=\"1100\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">John</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Smith</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">ate</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">pizza</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">yesterday!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9d550cd9488d48b8adabbf781f67318d-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9d550cd9488d48b8adabbf781f67318d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9d550cd9488d48b8adabbf781f67318d-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9d550cd9488d48b8adabbf781f67318d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9d550cd9488d48b8adabbf781f67318d-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9d550cd9488d48b8adabbf781f67318d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9d550cd9488d48b8adabbf781f67318d-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9d550cd9488d48b8adabbf781f67318d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9d550cd9488d48b8adabbf781f67318d-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9d550cd9488d48b8adabbf781f67318d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # # Linguistic Features # # #\n",
    "doc = analyze_text('John Smith ate a pizza yesterday!')\n",
    "\n",
    "for token in doc:\n",
    "    # The part-of-speech tag of the token head.\n",
    "    print('Part of speech', token.text, '-->', token.pos_)\n",
    "    # The syntactic relation connecting child to head.\n",
    "    print('Dependency parser', token.text, '-->', token.dep_)\n",
    "    # The original text of the token head.\n",
    "    print('Head Text', token.head.text, '-->', token.text)\n",
    "\n",
    "\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun phrase as adverbial modifier\n"
     ]
    }
   ],
   "source": [
    "spacy_explain('npadvmod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple --> ORG\n",
      "U.K. --> GPE\n",
      "$1 Billion --> MONEY\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 Billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # # Predicting Named Entities # # #\n",
    "\n",
    "doc = analyze_text('Apple is looking at buying U.K. startup for $1 Billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, '-->', ent.label_)\n",
    "\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "spacy_explain('GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text --> ['winning', 'won', 'wins', 'has']\n",
      "Lemma --> ['win', 'won', 'win', 'have']\n"
     ]
    }
   ],
   "source": [
    "# # # LEMMA attribute # # #\n",
    "# Lemma (Finds the root word \"win\" -> [\"won\", \"winning\", \"win\"]), \n",
    "# (Stemming “winning” -> “winn” and that’s not an english word!)\n",
    "\n",
    "def lemmatisation():\n",
    "    doc = analyze_text('winning won wins has')\n",
    "    print(\"Text -->\", [token.text for token in doc])\n",
    "    print(\"Lemma -->\", [token.lemma_ for token in doc])\n",
    "\n",
    "lemmatisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Efficient Phrase Matcher # # #\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sportsPatterns(sport):\n",
    "\treturn [\n",
    "\t\t{'IS_DIGIT': True},\n",
    "\t\t{'LOWER': f'{sport}', 'OP': '?'},\n",
    "\t\t{'LOWER': 'world'},\n",
    "\t\t{'LOWER': 'cup'},\n",
    "\t\t{'IS_PUNCT': True},\n",
    "\t]\n",
    "\n",
    "\n",
    "def emotionPatterns(emotion):\n",
    "\treturn [\n",
    "\t\t{'LEMMA': f'{emotion}', 'POS': 'VERB'},\n",
    "\t]\n",
    "\n",
    "\n",
    "def gadgetPatterns(gadget, extensionName):\n",
    "\treturn [\n",
    "\t\t{'LOWER': f'{gadget}'}, \n",
    "\t\t{'LOWER': f'{extensionName}', 'OP': '?'}\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa = sportsPatterns(sport='fifa')\n",
    "rugby = sportsPatterns(sport='rugby')\n",
    "\n",
    "love = emotionPatterns(emotion='love')\n",
    "hate = emotionPatterns(emotion='hate')\n",
    "\n",
    "phone = gadgetPatterns(gadget='iphone', extensionName='x')\n",
    "computer = gadgetPatterns(gadget='mac', extensionName=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matchers(matcher):\n",
    "\tmatcher.add(\"World_Cups\", [fifa, rugby]);\n",
    "\tmatcher.add(\"Emotion\", [love, hate]);\n",
    "\tmatcher.add(\"Gadgets\", [phone, computer]);\n",
    "\n",
    "\n",
    "add_matchers(matcher)\n",
    "\n",
    "def showMatcher(doc):\n",
    "\tmatches = matcher(doc)\n",
    "\tfor match_id, start, end in matches:\n",
    "\t\tstring_id = nlp.vocab.strings[match_id]  # Get string representation of matcher\n",
    "\t\tspan = doc[start:end]  # The matched span\n",
    "\t\tprint(\n",
    "\t\t\tf\"\"\"match_id: {match_id},\n",
    "string_id: {string_id},\n",
    "start: {start},\n",
    "end: {end},\n",
    "TEXT: {span.text}\n",
    "\t\t\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_id: 14626195295482834101,\n",
      "string_id: Gadgets,\n",
      "start: 1,\n",
      "end: 2,\n",
      "TEXT: Mac\n",
      "\t\t\n",
      "match_id: 12355752904639115815,\n",
      "string_id: World_Cups,\n",
      "start: 0,\n",
      "end: 5,\n",
      "TEXT: 2018 FIFA world cup:\n",
      "\t\t\n",
      "match_id: 12577823007746369398,\n",
      "string_id: Emotion,\n",
      "start: 1,\n",
      "end: 2,\n",
      "TEXT: loved\n",
      "\t\t\n",
      "match_id: 12577823007746369398,\n",
      "string_id: Emotion,\n",
      "start: 5,\n",
      "end: 6,\n",
      "TEXT: love\n",
      "\t\t\n",
      "match_id: 12577823007746369398,\n",
      "string_id: Emotion,\n",
      "start: 1,\n",
      "end: 2,\n",
      "TEXT: hate\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "def showRepresentationOfMatchers():\n",
    "\tdoc = analyze_text('Upcoming Mac Pro, has leaked the release date')\n",
    "\tdoc2 = analyze_text('2018 FIFA world cup: France won!')\n",
    "\tdoc3 = analyze_text('I loved dogs now I love cats more')\n",
    "\tdoc4 = analyze_text('I hate tomatoes')\n",
    "\tshowMatcher(doc)\n",
    "\tshowMatcher(doc2)\n",
    "\tshowMatcher(doc3)\n",
    "\tshowMatcher(doc4)\n",
    "\n",
    "\n",
    "showRepresentationOfMatchers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Efficient Phrase Matcher # # #\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "pattern = analyze_text('Golden Retriever')\n",
    "pattern2 = analyze_text('Golden Retriever')\n",
    "matcher.add('DOG', [pattern, pattern2])\n",
    "doc = nlp(\"I have a Golden Retriever\")\n",
    "\n",
    "\n",
    "for match_id, start, end in matcher(doc):\n",
    "    span = doc[start:end]\n",
    "    print('Matched phrase: ', span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Similarity # # #\n",
    "\n",
    "# # 2 documents\n",
    "doc1 = analyze_text('I like fast food')\n",
    "doc2 = analyze_text('I love pizza')\n",
    "print(f\"{round(doc1.similarity(doc2) * 100, 2)}%\")\n",
    "\n",
    "# # 2 tokens\n",
    "doc = analyze_text('I like pizza and pasta')\n",
    "print(f\"{round(doc[2].similarity(doc[4]) * 100, 2)}%\")\n",
    "\n",
    "# # document and token\n",
    "doc3 = analyze_text('I love pizza')\n",
    "token = analyze_text('soap')[0]\n",
    "print(f\"{round(doc3.similarity(token) * 100, 2)}%\")\n",
    "\n",
    "# span and document\n",
    "span = analyze_text('I like pizza and pasta')[2: 5]\n",
    "document = analyze_text('MacDonald\\'s sells burgers')\n",
    "\n",
    "print(f\"{round(span.similarity(document) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "596da59c3b517429896be298a7a92193c91659930c63f247802a5246489e9278"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5  ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}